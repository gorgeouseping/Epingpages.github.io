---
layout: archive
permalink: /year-archive/
title: "Benchmark Datasets"
author_profile: true
---
<div style="display: flex; align-items: center; width: 100%;">
  <div style="flex: 30%;">
    <a>
        <img src="https://github.com/gorgeouseping/Epingpages.github.io/raw/master/images/2DInsight3D.png" alt="2DInsight3D" style="width: 90%;"/>
    </a>
  </div>
  <div style="flex: 70%;">
    <strong>2DInsight3D</strong> is a multi-modal dataset for non-labeled point cloud semantic segmentation, containing aligned remote sensing images and MLS point cloud. The remote sensing data were acquired using images captured by the Gaofen-2 (GF-2) optical remote sensing satellite with a 4-metre resolution across four spectral bands, and annotated in ten prominent land cover categories. The point cloud part consists of approximately 444 million points captured using the RIEGL VMX-450 mobile laser scanning system. It is defined 8 urban scenes labels: water, soil, vegetation, building, highway, other roads, cars and unclassified.<br>
  </div>
</div>
<br>
<div style="display: flex; align-items: center; width: 100%;">
  <div style="flex: 30%;">
    <a>
        <img src="https://github.com/Ting-Devin-Han/Epingpages.github.io/raw/master/images/JMC.gif" alt="JMC" style="width: 90%;"/>
        <img src="https://github.com/Ting-Devin-Han/Epingpages.github.io/raw/master/images/CAR.gif" alt="CAR" style="width: 90%;"/>
        <img src="https://github.com/Ting-Devin-Han/Epingpages.github.io/raw/master/images/XHR.gif" alt="XHR" style="width: 90%;"/>
        <img src="https://github.com/Ting-Devin-Han/Epingpages.github.io/raw/master/images/YWR.gif" alt="YWR" style="width: 90%;"/>
    </a>
  </div>
  <div style="flex: 70%;">
    <strong>City-Facade</strong> is a large-scale urban building facade dataset for semantic-level and instance-level segmentation from MLS LiDAR point clouds. It consists of labeled point clouds (with 9 classes for building facades) as well as unlabeled data (point clouds of street landscapes). The data collection area encompasses a variety of streets in Xiamen, China, with distinct architectural styles. We believe that our City-Facade will faciliate feature research on point cloud semantic or instance segmentation, urban understanding and modeling, point cloud completion, etc. Welcome to download and make use of City-Facade.<br>
    <!-- <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Chen_LiDAR-Video_Driving_Dataset_CVPR_2018_paper.html">PaperüìÑ</a>| -->
    <a href="https://github.com/Ting-Devin-Han/City-Facade">Codeüíª</a>
    <!-- <a href="http://www.dbehavior.net/">HomePageüè†</a> -->
  </div>
</div>
<br>
<div style="display: flex; align-items: center; width: 100%;">
  <div style="flex: 30%;">
    <a>
        <img src="https://github.com/gorgeouseping/Epingpages.github.io/raw/master/images/SYSU9.png" alt="SYSU9" style="width: 90%;"/>
    </a>
  </div>
  <div style="flex: 70%;">
    <strong>SYSU9</strong> dense point cloud dataset for large-scale semantic segmentation. The SYSU9 dataset mainly includes the sequence point clouds of the Zhuhai campus of Sun Yat-sen University. The data size is about 3 km by 2 km in length by width, totaling about 200 million points. About over 15 types of features were collected, of which evaluated 9 types of features, including roads, sidewalks, natural ground, trees, grass, vehicles, buildings, transportation facilities, and man-made terrain.<br>
    <a href="https://www.sciencedirect.com/science/article/pii/S1569843224003054">PaperüìÑ</a>
  </div>
</div>
<br>
<div style="display: flex; align-items: center; width: 100%;">
  <div style="flex: 30%;">
    <a>
        <img src="https://github.com/gorgeouseping/Epingpages.github.io/raw/master/images/Crack-UNet.png" alt="Crack-UNet" style="width: 90%;"/>
    </a>
  </div>
  <div style="flex: 70%;">
    <strong>Crack-Road</strong> were divided from the point cloud data of the Qinghai Tibet Highway to form point cloud road surface crack dataset. In addition, the width and length of each segments in the dataset are about 10 meters, and the average number of points contained in each road surface point cloud is 200,000.<br>
  </div>
</div>
<br>
<div style="display: flex; align-items: center; width: 100%;">
  <div style="flex: 30%;">
    <a>
        <img src="https://github.com/gorgeouseping/Epingpages.github.io/raw/master/images/MGRoad.png" alt="MGRoad" style="width: 90%;"/>
    </a>
  </div>
  <div style="flex: 70%;">
    <strong>MGRoad</strong> is a road classification dataset used for road grade discrimination and segmentation in images. The image resolution is 0.8m, and the roads are divided into high, medium and low grades according to the expressway and expressway, first-class highway, second-class highway and Class III road. Covering multiple scenarios such as rural, urban, and suburban areas.<br>
  </div>
</div>
<br>
<div style="display: flex; align-items: center; width: 100%;">
  <div style="flex: 30%;">
    <a>
        <img src="https://github.com/Ting-Devin-Han/Epingpages.github.io/raw/master/images/DBNet.gif" alt="DBNet" style="width: 90%;"/>
    </a>
  </div>
  <div style="flex: 70%;">
    <strong>DBNet</strong> is a comprehensive large-scale dataset that includes 3D point cloud data, video images, GNSS data, and driver behavior metrics such as speed and direction. It Covers over 1,000 kilometres in Xiamen with different types of roads. DBNet provides city-level 3D point cloud with coresponding 2D video images, serving as a robust foundation for decision-making in autonomous driving. It has been widely used by more than 600 organizations and individuals across the world, including MIT, Google, etc. Welcome to download and make use of DBNet.<br>
    <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Chen_LiDAR-Video_Driving_Dataset_CVPR_2018_paper.html">PaperüìÑ</a>|
    <a href="https://github.com/driving-behavior/DBNet">Codeüíª</a>|
    <a href="http://www.dbehavior.net/">HomePageüè†</a>
  </div>
</div>

